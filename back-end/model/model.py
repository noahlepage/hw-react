#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Speaker Identification with Transfer Learning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VcvuLWpf_BU34KIlJg8aGP6H1eAhUCO7
"""
import os
from os.path import isfile, join
import tensorflow as tf
import numpy as np
import shutil
from tensorflow import keras
from pathlib import Path
from IPython.display import display, Audio
import subprocess
import opendatasets as od

from pydub import AudioSegment as am
import librosa
import matplotlib.pyplot as plt
from matplotlib.pyplot import specgram

from keras.applications import VGG16
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.models import Model
from keras import utils

from sklearn.preprocessing import LabelEncoder
from sklearn import svm
from sklearn.metrics import accuracy_score
from joblib import dump

def get_file_name(file : str) -> str:
  return file[:-4]

raw_data = "./data/raw_data"
processed_data = "./data/processed_data"
chunks = "./data/processed_data/chunks"
specs_path = "./data/processed_data/specs"

# ===================================================== PRE-PROCESSING =========================================== #
# mounted_data = "./drive/MyDrive/McHacks/raw_data"
# raw_data = "./raw_data"

# for file in os.listdir(mounted_data):
#   shutil.copy(os.path.join(mounted_data, file), "./raw_data")

for file in os.listdir(raw_data):
  if os.path.isfile(os.path.join(raw_data, file)):
    sound = am.from_file(os.path.join(raw_data, file), format='m4a')
    fh = sound.export(os.path.join(processed_data, get_file_name(file) + ".wav"), format='wav')

for file in os.listdir(processed_data):
  curr_file = os.path.join(processed_data, file)
  if os.path.isfile(curr_file):
    out_file = os.path.join(chunks, get_file_name(file) + "%03d.wav")
    subprocess.call(['ffmpeg', '-i', curr_file, '-f', 'segment',
               '-segment_time', '1', '-c', 'copy', out_file])

def save_spec(sound, sr, path : str) -> None:
    fig, ax = plt.subplots(1)
    plt.axis('off')
    specgram(np.array(sound), Fs=sr)
    plt.savefig(path, bbox_inches='tight', pad_inches=0)
    plt.close(fig)

saved_shape = None
for file in os.listdir(chunks):
  curr_file = os.path.join(chunks, file)
  if os.path.isdir(curr_file) or '000' in file: # remove unfinshed spectrogram
    continue
  out_file = os.path.join(specs_path, get_file_name(file) + ".jpg")
  sound, sr = librosa.load(curr_file)
  save_spec(sound, sr, out_file)

  if saved_shape is None:
    saved_shape = plt.imread(out_file).shape

# Load "new" data
def get_person_name(file_name : str, path_exclude='') -> str:
  return file_name[:-7].replace(path_exclude + "/", '')

spect_files = []
spects = []
spect_ids = []

for file in os.listdir(specs_path):
  curr_file = os.path.join(specs_path, file)
  if os.path.isdir(curr_file):
    continue
  spect = plt.imread(curr_file)
  if spect.shape == saved_shape:
    spects.append(spect)
    spect_ids.append(get_person_name(curr_file, specs_path))
    spect_files.append(file)

shuffle_seed = 420
valid_split = 0.3

def shuffle_dataset(spects, labels):
  rng = np.random.RandomState(shuffle_seed)
  rng.shuffle(spects)
  rng = np.random.RandomState(shuffle_seed)
  rng.shuffle(labels)

shuffle_dataset(spects, spect_ids)

cut_off = int(valid_split * len(spects))
x_train = spects[:-cut_off] # data
y_train = spect_ids[:-cut_off] # labels
x_test = spects[-cut_off:]
y_test = spect_ids[-cut_off:]
print(y_test)

# Encoding
def encode_labels(labels):
  encoder = LabelEncoder()
  labels_copy = np.copy(labels)
  encoder.fit(labels_copy)
  encoded = encoder.transform(labels_copy)
  encoded = utils.to_categorical(encoded)
  return encoded

encoded_train = encode_labels(y_train)
encoded_test = encode_labels(y_test)
encoded_test

# =============================== Transfer Learning ======================== #
vgg_model = VGG16(weights='imagenet',include_top=False, input_shape=saved_shape)

for i,layer in enumerate(vgg_model.layers):
  layer.trainable = False

x = vgg_model.output
x = Flatten(name="Flatten")(x) # Flatten dimensions to for use in FC layers
trained_model = Model(inputs=vgg_model.input, outputs=x)
transfer_model = Model(inputs=trained_model.input, outputs=trained_model.get_layer('Flatten').output)

# Extracting features
def predict_features(spects, labels):
  svm_spects = []
  svm_labels = []

  for i in range(len(spects)):
    x = np.expand_dims(spects[i], axis=0)
    features = transfer_model.predict(x)
    svm_spects.append(features)
    svm_labels.append(labels[i])
  return (svm_spects, svm_labels)

svm_x_train, svm_y_train = predict_features(x_train, encoded_train)
svm_x_test, svm_y_test = predict_features(x_test, encoded_test)

def convert_binary_to_numerical_encoding(spects, labels):
  dataset_size = len(spects)
  svm_spects = np.array(spects).reshape(dataset_size,-1)
  svm_labels = [np.where(r==1)[0][0] for r in labels]
  return (svm_spects, svm_labels)

svm_x_train, svm_y_train = convert_binary_to_numerical_encoding(svm_x_train, svm_y_train)
svm_x_test, svm_y_test = convert_binary_to_numerical_encoding(svm_x_test, svm_y_test)

clf = svm.SVC(kernel='rbf', class_weight='balanced', probability=True)
clf.fit(svm_x_train, svm_y_train)

print(accuracy_score(svm_y_test, clf.predict(svm_x_test)))
dump(clf, 'saved_model.joblib')